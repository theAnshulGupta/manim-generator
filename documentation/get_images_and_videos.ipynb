{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa88f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "import os\n",
    "import base64\n",
    "import cv2\n",
    "from anthropic import AsyncAnthropic\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cebf6a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINK_PREFIX = \"https://docs.manim.community/en/stable/\"\n",
    "MEDIA_OUTPUT_DIR = \"downloaded_media\"\n",
    "SUMMARY_OUTPUT_DIR = \"summary\"\n",
    "INPUT_DIR = \"page_content\"\n",
    "\n",
    "client = AsyncAnthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97eb846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_to_file_name(link):\n",
    "    return link[39:].replace('/', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b13029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_and_media(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    soup = BeautifulSoup(data, \"html.parser\")\n",
    "    media_tags = soup.find_all([\"img\", \"video\"])\n",
    "    marker = \"<<<MEDIA>>>\"\n",
    "    media_list = []\n",
    "\n",
    "    # Get images and replace all of them with marker\n",
    "    for tag in media_tags:\n",
    "        if tag.name == \"img\":\n",
    "            src = tag.get(\"src\") or tag.get(\"data‑src\")\n",
    "            media_list.append((\"image\", src))\n",
    "        else:\n",
    "            src = tag.get(\"src\")\n",
    "            if not src and tag.find(\"source\"):\n",
    "                src = tag.find(\"source\").get(\"src\")\n",
    "            media_list.append((\"video\", src))\n",
    "        tag.replace_with(marker)\n",
    "\n",
    "    # Get all the texts and split based on marker\n",
    "    full_text = soup.get_text()\n",
    "    parts = [piece.strip() for piece in full_text.split(marker)]\n",
    "\n",
    "    # Interleave\n",
    "    result = []\n",
    "    for i, media in enumerate(media_list):\n",
    "        if parts[i]:\n",
    "            result.append((\"text\", parts[i]))\n",
    "        result.append(media)\n",
    "    if len(parts) > len(media_list) and parts[-1]:\n",
    "        result.append((\"text\", parts[-1]))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1e58249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images_and_videos(url, content):\n",
    "    session = requests.Session()\n",
    "\n",
    "    for t, info in content:\n",
    "        if t == \"image\" or t == \"video\":\n",
    "            full_url = urljoin(url, info)\n",
    "            response = session.get(full_url)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                with open(f\"{MEDIA_OUTPUT_DIR}/{link_to_file_name(full_url)}\", \"wb\") as f:\n",
    "                    f.write(response.content)\n",
    "                print(f\"[saved] {link_to_file_name(full_url)}\")\n",
    "            else:\n",
    "                print(f\"[failed] {full_url} (status code {response.status_code})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c237cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_message(url, content):\n",
    "    message_content = []\n",
    "\n",
    "    for t, info in content:\n",
    "        if t == \"image\":\n",
    "            full_url = urljoin(url, info)\n",
    "            path = os.path.join(MEDIA_OUTPUT_DIR, link_to_file_name(full_url))\n",
    "\n",
    "            # No svg\n",
    "            if path[-3:] == \"svg\":\n",
    "                continue\n",
    "\n",
    "            with open(path, \"rb\") as f:\n",
    "                image_data = f.read()\n",
    "\n",
    "            message_content.append({\n",
    "                \"type\": \"image\",\n",
    "                \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": \"image/png\",\n",
    "                    \"data\": base64.standard_b64encode(image_data).decode(\"utf-8\"),\n",
    "                }\n",
    "            })\n",
    "\n",
    "        elif t == \"video\":\n",
    "            # Extract middle frame\n",
    "            full_url = urljoin(url, info)\n",
    "            path = os.path.join(MEDIA_OUTPUT_DIR, link_to_file_name(full_url))\n",
    "            cap = cv2.VideoCapture(path)\n",
    "            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            middle_frame_idx = frame_count // 2\n",
    "\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, middle_frame_idx)\n",
    "            _, frame = cap.read()\n",
    "            cap.release()\n",
    "            _, buffer = cv2.imencode(\".png\", frame)\n",
    "            image_data = buffer.tobytes()\n",
    "\n",
    "            message_content.append({\n",
    "                \"type\": \"image\",\n",
    "                \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": \"image/png\",\n",
    "                    \"data\": base64.standard_b64encode(image_data).decode(\"utf-8\"),\n",
    "                }\n",
    "            })\n",
    "        else:\n",
    "            message_content.append({ \"type\": \"text\", \"text\": info })\n",
    "    \n",
    "    return { \"role\": \"user\", \"content\": message_content }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f906082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_save():\n",
    "    for file_name in os.listdir(INPUT_DIR):\n",
    "        path = os.path.join(INPUT_DIR, file_name)\n",
    "        \n",
    "        with open(path, \"rb\") as f:\n",
    "            url = f.readline().decode('utf-8').strip()\n",
    "        \n",
    "        content = extract_text_and_media(path)\n",
    "        save_images_and_videos(url, content)\n",
    "\n",
    "# run_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18e92cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexl\\AppData\\Local\\Temp\\ipykernel_4140\\901300213.py:2: RuntimeWarning: coroutine 'AsyncMessages.create' was never awaited\n",
      "  results = []\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "100%|██████████| 539/539 [01:07<00:00,  7.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# Construct all summaries\n",
    "results = []\n",
    "\n",
    "for file_name in tqdm(os.listdir(INPUT_DIR)):\n",
    "    path = os.path.join(INPUT_DIR, file_name)\n",
    "    \n",
    "    with open(path, \"rb\") as f:\n",
    "        url = f.readline().decode('utf-8').strip()\n",
    "    \n",
    "    content = extract_text_and_media(path)\n",
    "    user_message = [construct_message(url, content)]\n",
    "    \n",
    "    query = client.messages.create(\n",
    "        model=\"claude-3-5-haiku-20241022\",\n",
    "        temperature=1,\n",
    "        max_tokens=8192,\n",
    "        system=\"You are an expert technical writer. You will be given the content of some documentation for the Manim library. Please summarize the information you are given but do so such that someone with no experience can still get the same amount of information from the summary (feel free to include the examples) but also try to keep it as short as possible to minimize token use (pretty important). Also, if you believe the information is not relevant or important for an average user to code in Manim, you can simply say 'Not relevant' -- keep your standards high, for example something like the changelog or how to contribute isn't important. Just to reiterate, unimportant things like the changelog should not be summarized and you should just say 'Not relevant' -- really make sure that only the actually absolute necessary things in the documentation are summarized. Only include your reponse/summary and absolutely nothing more, don't have any unnecessary comments (since minimizing response length is really important). To reiterate again, make the response as short as possible!\",\n",
    "        messages=user_message\n",
    "    )\n",
    "    results.append((file_name, query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69d41638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [1:28:40<00:00,  9.87s/it]\n"
     ]
    }
   ],
   "source": [
    "for file_name, query in tqdm(results):\n",
    "    query = await query\n",
    "    info = query.content[0].text\n",
    "\n",
    "    with open(os.path.join(SUMMARY_OUTPUT_DIR, file_name), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
