{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e6f3d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import anthropic\n",
    "from bs4 import BeautifulSoup\n",
    "import base64\n",
    "from urllib.parse import urljoin\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "client = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c99e1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"page_content\"\n",
    "EXAMPLE_DIR = \"examples\"\n",
    "SUMMARY_DIR = \"summary\"\n",
    "MEDIA_OUTPUT_DIR = \"downloaded_media\"\n",
    "\n",
    "SYSTEM = \"\"\"\n",
    "You are an agent that is an expert at Manim, a Python library that can be compiled to create video tutorials for educational materials. Your task is to take in a textbook chapter covering some material and create an educational tutorial using Manim, detailing technical parts of the textbook to make it intuitive. Feel free to create a voice over with the manim voiceover feature and explore the documentation. However, make sure that your final output is the manim code only and nothing more (so once you have the code **DO NOT OUTPUT ANYTHING ELSE OTHER THAN THE CODE**)! The idea is to have different sections covering the topic, with visualizations of mathematical concepts and explanatory text as needed. Ensure the absolute highest accuracy possible by using the documentation in order to prrevent any mistakes.\n",
    "\n",
    "First, understand the topic at hand. If there are multiple, focus on the first one and then iterate through the rest. Then, understand how the textbook conveys material and equations. If there is a lot of material to cover, break it up into sections, processing each section at a time. Make it such that a beginner new to this field understands it.\n",
    "\n",
    "Ensure that your Manim tutorial goes in depth to each of these topics, creating a detailed video of at least a minute explaining the topic, having an example, and ending in a summary. Compile all the events in a term called FullTutorial. Additionally, if you need to include equations, ensure that you write it in LaTeX that can be compiled accurately. It is essential that you write safe LaTeX that only uses valid characters and formatting such that there are no issues with it. Use other materials like graphs or plots as well. When writing the steps of each topic using the Manim Community library in Python, ensuring that your code works correctly. Output a valid solution that can be run, producing a correct video without any errors whatsoever. Ensure that the text all fits in the screen and does not overlap with one another. I will provide several example input outputs to you as well initially.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "34e0ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples\n",
    "SYSTEM += \"\\n\\n===\\nBelow are a few examples\\n\\n\"\n",
    "\n",
    "for file_name in os.listdir(EXAMPLE_DIR):\n",
    "    path = os.path.join(EXAMPLE_DIR, file_name)\n",
    "    \n",
    "    with open(path, \"rb\") as f:\n",
    "        if \"in\" in file_name:\n",
    "            SYSTEM += \"Input:\\n\"\n",
    "        else:\n",
    "            SYSTEM += \"Output:\\n\"\n",
    "        \n",
    "        SYSTEM += str(f.read()) + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aefb6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [00:00<00:00, 2847.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Documentation\n",
    "SYSTEM += \"\\n===\\nYou will be provided the full documentation of the Manim. You can find the full set of page links and associated summary of the given page of documentation below. To view the actual details of some given documentation, feel free to call the function aivailable to you. Don't be afraid to do tthis as accuracy is your highest priority!\\n\\n\"\n",
    "\n",
    "for file_name in tqdm(os.listdir(INPUT_DIR)):\n",
    "    path_html = os.path.join(INPUT_DIR, file_name)\n",
    "    path_summ = os.path.join(SUMMARY_DIR, file_name.replace(\"html\", \"txt\"))\n",
    "\n",
    "    with open(path_html, \"rb\") as f:\n",
    "        url = f.readline().decode('utf-8').strip()\n",
    "    \n",
    "    with open(path_summ, \"rb\") as f:\n",
    "        SYSTEM += f\"{url}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "976a5193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136358.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SYSTEM) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_to_file_name(link):\n",
    "    return link[39:].replace('/', '.')\n",
    "\n",
    "def extract_text_and_media(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    soup = BeautifulSoup(data, \"html.parser\")\n",
    "    media_tags = soup.find_all([\"img\", \"video\"])\n",
    "    marker = \"<<<MEDIA>>>\"\n",
    "    media_list = []\n",
    "\n",
    "    # Get images and replace all of them with marker\n",
    "    for tag in media_tags:\n",
    "        if tag.name == \"img\":\n",
    "            src = tag.get(\"src\") or tag.get(\"data‑src\")\n",
    "            media_list.append((\"image\", src))\n",
    "        else:\n",
    "            src = tag.get(\"src\")\n",
    "            if not src and tag.find(\"source\"):\n",
    "                src = tag.find(\"source\").get(\"src\")\n",
    "            media_list.append((\"video\", src))\n",
    "        tag.replace_with(marker)\n",
    "\n",
    "    # Get all the texts and split based on marker\n",
    "    full_text = soup.get_text()\n",
    "    parts = [piece.strip() for piece in full_text.split(marker)]\n",
    "\n",
    "    # Interleave\n",
    "    result = []\n",
    "    for i, media in enumerate(media_list):\n",
    "        if parts[i]:\n",
    "            result.append((\"text\", parts[i]))\n",
    "        result.append(media)\n",
    "    if len(parts) > len(media_list) and parts[-1]:\n",
    "        result.append((\"text\", parts[-1]))\n",
    "\n",
    "    return result\n",
    "\n",
    "def construct_message(url, content):\n",
    "    message_content = []\n",
    "\n",
    "    for t, info in content:\n",
    "        if t == \"image\":\n",
    "            full_url = urljoin(url, info)\n",
    "            path = os.path.join(MEDIA_OUTPUT_DIR, link_to_file_name(full_url))\n",
    "\n",
    "            # No svg\n",
    "            if path[-3:] == \"svg\":\n",
    "                continue\n",
    "\n",
    "            with open(path, \"rb\") as f:\n",
    "                image_data = f.read()\n",
    "\n",
    "            message_content.append({\n",
    "                \"type\": \"image\",\n",
    "                \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": \"image/png\",\n",
    "                    \"data\": base64.standard_b64encode(image_data).decode(\"utf-8\"),\n",
    "                }\n",
    "            })\n",
    "\n",
    "        elif t == \"video\":\n",
    "            # Extract middle frame\n",
    "            full_url = urljoin(url, info)\n",
    "            path = os.path.join(MEDIA_OUTPUT_DIR, link_to_file_name(full_url))\n",
    "            cap = cv2.VideoCapture(path)\n",
    "            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            middle_frame_idx = frame_count // 2\n",
    "\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, middle_frame_idx)\n",
    "            _, frame = cap.read()\n",
    "            cap.release()\n",
    "            _, buffer = cv2.imencode(\".png\", frame)\n",
    "            image_data = buffer.tobytes()\n",
    "\n",
    "            message_content.append({\n",
    "                \"type\": \"image\",\n",
    "                \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": \"image/png\",\n",
    "                    \"data\": base64.standard_b64encode(image_data).decode(\"utf-8\"),\n",
    "                }\n",
    "            })\n",
    "        else:\n",
    "            message_content.append({ \"type\": \"text\", \"text\": info })\n",
    "    \n",
    "    return { \"role\": \"user\", \"content\": message_content }\n",
    "\n",
    "def send_query(url):\n",
    "    path = os.path.join(INPUT_DIR, link_to_file_name(url))\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        return \"Provided url {url} does not exist. Please provide an existitng one\"\n",
    "    \n",
    "    content = extract_text_and_media(path)\n",
    "    return str(construct_message(url, content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6c8ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[content]\n",
      "TextBlock(citations=None, text=\"I'll create a Manim animation to explain and visualize the vector semantics and embedding equations. Let me first check some relevant documentation to ensure I use Manim's features effectively.\", type='text')\n",
      "\n",
      "[query]\n",
      "https://docs.manim.community/en/stable/reference/manim.mobject.text.tex_mobject.MathTex.html\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'io' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_use\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[query]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(info\u001b[38;5;241m.\u001b[39minput[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msend_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     has_tool_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     messages\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [info],\n\u001b[0;32m     47\u001b[0m     })\n",
      "Cell \u001b[1;32mIn[66], line 110\u001b[0m, in \u001b[0;36msend_query\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvided url \u001b[39m\u001b[38;5;132;01m{url}\u001b[39;00m\u001b[38;5;124m does not exist. Please provide an existitng one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m content \u001b[38;5;241m=\u001b[39m extract_text_and_media(path)\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[43mconstruct_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[66], line 57\u001b[0m, in \u001b[0;36mconstruct_message\u001b[1;34m(url, content)\u001b[0m\n\u001b[0;32m     54\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mresize((img\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, img\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m), Image\u001b[38;5;241m.\u001b[39mLANCZOS)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# recompress as JPEG at 30% quality\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[0;32m     58\u001b[0m img\u001b[38;5;241m.\u001b[39msave(buf, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJPEG\u001b[39m\u001b[38;5;124m\"\u001b[39m, quality\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m     59\u001b[0m data \u001b[38;5;241m=\u001b[39m buf\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'io' is not defined"
     ]
    }
   ],
   "source": [
    "user_query = \"\"\n",
    "\n",
    "with open(\"prompt.txt\", \"rb\") as f:\n",
    "    user_query = str(f.read())\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": user_query + \"\\n\\nWhen you have the final working code, make sure to output it and nothing more. So when you are ready with the final code, ONLY output it -- don't include text like 'After compiling data', 'Now, based on this research', etc. -- just include the code and nothing more. Feel free to try to include a lot of visuals to make the code look nice. Furthermore, make sure to reference the documentation via the aivailable function in order to maximize accuracy! Don't go overboard with looking absolutely everything up -- just do what you think will help you produce the best results. Finally, DO NOT use any special unicode characters that might even remotely have a chance of causing issues with some latex interpreters!\"\n",
    "}]\n",
    "\n",
    "while True:\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-7-sonnet-20250219\",\n",
    "        max_tokens=15000,\n",
    "        temperature=1,\n",
    "        system=SYSTEM,\n",
    "        tools = [\n",
    "            {\n",
    "                \"name\": \"get_specific_documentatino_info\",\n",
    "                \"description\": \"Gets specific documentation info from provided url\",\n",
    "                \"input_schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"url\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"URL whose documentation info you want returned.\"\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"url\"]\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    has_tool_call = False\n",
    "    \n",
    "    for info in message.content:\n",
    "        if info.type == \"tool_use\":\n",
    "            print(\"[query]\\n\" + str(info.input[\"url\"]) + \"\\n\")\n",
    "            result = send_query(info.input[\"url\"])\n",
    "            has_tool_call = True\n",
    "\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": [info],\n",
    "            })\n",
    "            messages.append({\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\n",
    "                    \"type\": \"tool_result\",\n",
    "                    \"tool_use_id\": info.id,\n",
    "                    \"content\": result,\n",
    "                    \"cache_control\": {\"type\": \"ephemeral\"}\n",
    "                }]\n",
    "            })\n",
    "        \n",
    "        else:\n",
    "            print(\"[content]\\n\" + str(info) + \"\\n\")\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": [info],\n",
    "            })\n",
    "    \n",
    "    if not has_tool_call:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a655b7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, based on all this research and the documentation, I'll create a comprehensive educational video on vector semantics and embeddings using Manim.\n",
      "\n",
      "```python\n",
      "from manim import *\n",
      "import numpy as np\n",
      "\n",
      "class VectorSemanticsAndEmbeddings(Scene):\n",
      "    def construct(self):\n",
      "        # Title Scene\n",
      "        self.title_scene()\n",
      "        \n",
      "        # Introduction to Vector Semantics\n",
      "        self.intro_section()\n",
      "        \n",
      "        # Dot Product\n",
      "        self.dot_product_section()\n",
      "        \n",
      "        # Cosine Similarity\n",
      "        self.cosine_similarity_section()\n",
      "        \n",
      "        # Term Frequency (TF)\n",
      "        self.tf_section()\n",
      "        \n",
      "        # Inverse Document Frequency (IDF)\n",
      "        self.idf_section()\n",
      "        \n",
      "        # TF-IDF\n",
      "        self.tfidf_section()\n",
      "        \n",
      "        # PMI and PPMI\n",
      "        self.pmi_section()\n",
      "        \n",
      "        # Skip-Gram Model\n",
      "        self.skipgram_section()\n",
      "        \n",
      "        # Conclusion\n",
      "        self.conclusion_section()\n",
      "\n",
      "    def title_scene(self):\n",
      "        title = Text(\"Vector Semantics and Embeddings\", font_size=72)\n",
      "        subtitle = Text(\"Understanding Word Meaning in Vector Space\", font_size=36)\n",
      "        subtitle.next_to(title, DOWN, buff=0.5)\n",
      "        \n",
      "        self.play(Write(title), run_time=2)\n",
      "        self.play(FadeIn(subtitle, shift=UP*0.5))\n",
      "        self.wait(2)\n",
      "        self.play(FadeOut(title), FadeOut(subtitle))\n",
      "    \n",
      "    def intro_section(self):\n",
      "        intro_title = Text(\"Introduction to Vector Semantics\", font_size=60)\n",
      "        intro_title.to_edge(UP)\n",
      "        \n",
      "        intro_text = MarkupText(\n",
      "            \"Vector semantics represents word meaning by <b>embedding</b> words\\n\"\n",
      "            \"into a mathematical vector space where semantically\\n\"\n",
      "            \"similar words are represented by similar vectors.\", font_size=36\n",
      "        )\n",
      "        intro_text.next_to(intro_title, DOWN, buff=0.8)\n",
      "        \n",
      "        # Create a simple 2D word vector space visualization\n",
      "        plane = NumberPlane(\n",
      "            x_range=[-3, 3, 1],\n",
      "            y_range=[-3, 3, 1],\n",
      "            background_line_style={\n",
      "                \"stroke_opacity\": 0.5,\n",
      "                \"stroke_width\": 1,\n",
      "            }\n",
      "        ).scale(0.8)\n",
      "        \n",
      "        # Create some word vectors\n",
      "        word_vectors = {\n",
      "            \"king\": np.array([2, 1, 0]),\n",
      "            \"queen\": np.array([2, -1, 0]),\n",
      "            \"man\": np.array([1, 1, 0]),\n",
      "            \"woman\": np.array([1, -1, 0]),\n",
      "            \"dog\": np.array([-2, 0.5, 0]),\n",
      "            \"cat\": np.array([-2, -0.5, 0]),\n",
      "        }\n",
      "        \n",
      "        words = VGroup()\n",
      "        for word, vec in word_vectors.items():\n",
      "            dot = Dot(plane.coords_to_point(*vec), color=BLUE)\n",
      "            label = Text(word, font_size=24).next_to(dot, UP*0.5)\n",
      "            words.add(VGroup(dot, label))\n",
      "        \n",
      "        vector_space = VGroup(plane, words).to_edge(DOWN, buff=0.5)\n",
      "        \n",
      "        self.play(Write(intro_title))\n",
      "        self.play(FadeIn(intro_text))\n",
      "        self.wait()\n",
      "        self.play(FadeIn(vector_space))\n",
      "        self.wait(2)\n",
      "        \n",
      "        # Draw the \"royal\" direction arrow\n",
      "        royal_arrow = Arrow(\n",
      "            plane.coords_to_point(0, 0, 0),\n",
      "            plane.coords_to_point(2, 0, 0),\n",
      "            buff=0,\n",
      "            color=YELLOW\n",
      "        )\n",
      "        royal_label = Text(\"'royal' dimension\", font_size=20, color=YELLOW).next_to(royal_arrow, UP)\n",
      "        \n",
      "        # Draw the \"gender\" direction arrow\n",
      "        gender_arrow = Arrow(\n",
      "            plane.coords_to_point(0, 0, 0),\n",
      "            plane.coords_to_point(0, 1, 0),\n",
      "            buff=0,\n",
      "            color=GREEN\n",
      "        )\n",
      "        gender_label = Text(\"'gender' dimension\", font_size=20, color=GREEN).next_to(gender_arrow, RIGHT)\n",
      "        \n",
      "        self.play(\n",
      "            Create(royal_arrow),\n",
      "            Write(royal_label),\n",
      "        )\n",
      "        self.wait()\n",
      "        self.play(\n",
      "            Create(gender_arrow),\n",
      "            Write(gender_label),\n",
      "        )\n",
      "        self.wait(2)\n",
      "        \n",
      "        self.play(\n",
      "            FadeOut(intro_title),\n",
      "            FadeOut(intro_text),\n",
      "            FadeOut(vector_space),\n",
      "            FadeOut(royal_arrow),\n",
      "            FadeOut(royal_label),\n",
      "            FadeOut(gender_arrow),\n",
      "            FadeOut(gender_label)\n",
      "        )\n",
      "\n",
      "    def dot_product_section(self):\n",
      "        title = Text(\"Dot Product\", font_size=60)\n",
      "        title.to_edge(UP)\n",
      "        \n",
      "        dot_product_def = MathTex(\n",
      "            r\"\\text{dot product}(v, w) = v \\cdot w = \\sum_{i=1}^{N} v_i w_i = v_1 w_1 + v_2 w_2 + \\cdots + v_N w_N\",\n",
      "            font_size=36\n",
      "        )\n",
      "        dot_product_def.next_to(title, DOWN, buff=0.8)\n",
      "        \n",
      "        explanation = Text(\n",
      "            \"Dot product measures the similarity between two vectors,\\n\"\n",
      "            \"or how much one vector 'points in the direction' of another.\",\n",
      "            font_size=30\n",
      "        )\n",
      "        explanation.next_to(dot_product_def, DOWN, buff=0.5)\n",
      "        \n",
      "        self.play(Write(title))\n",
      "        self.play(Write(dot_product_def), run_time=2)\n",
      "        self.play(FadeIn(explanation))\n",
      "        self.wait()\n",
      "        \n",
      "        # Create a visualization of dot product\n",
      "        plane = NumberPlane(\n",
      "            x_range=[-3, 3, 1],\n",
      "            y_range=[-3, 3, 1],\n",
      "        ).scale(0.6)\n",
      "        plane.to_edge(DOWN, buff=0.5)\n",
      "        \n",
      "        vec1 = Vector([2, 1], color=BLUE, tip_length=0.2)\n",
      "        vec2 = Vector([1, 2], color=RED, tip_length=0.2)\n",
      "        \n",
      "        vec1_label = MathTex(r\"\\vec{v}\", color=BLUE).next_to(vec1.get_end(), RIGHT*0.5)\n",
      "        vec2_label = MathTex(r\"\\vec{w}\", color=RED).next_to(vec2.get_end(), UP*0.5)\n",
      "        \n",
      "        vector_group = VGroup(plane, vec1, vec2, vec1_label, vec2_label)\n",
      "        \n",
      "        self.play(FadeIn(vector_group))\n",
      "        self.wait()\n",
      "        \n",
      "        # Calculate dot product visually\n",
      "        dot_product_calc = MathTex(\n",
      "            r\"\\vec{v} \\cdot \\vec{w} &= (2, 1) \\cdot (1, 2)\\\\\",\n",
      "            r\"&= 2 \\cdot 1 + 1 \\cdot 2\\\\\",\n",
      "            r\"&= 2 + 2\\\\\",\n",
      "            r\"&= 4\"\n",
      "        )\n",
      "        dot_product_calc.scale(0.8).to_edge(RIGHT, buff=0.8)\n",
      "        \n",
      "        self.play(Write(dot_product_calc), run_time=3)\n",
      "        \n",
      "        # Show projection visualization\n",
      "        proj_line = DashedLine(vec2.get_end(), [2, 1, 0], color=YELLOW)\n",
      "        proj_vec = Vector([2, 1], color=YELLOW, tip_length=0)\n",
      "        proj_text = Text(\"Projection\", font_size=24, color=YELLOW).next_to(proj_line, UP)\n",
      "        \n",
      "        self.play(\n",
      "            Create(proj_line),\n",
      "            FadeIn(proj_text)\n",
      "        )\n",
      "        self.wait(2)\n",
      "        \n",
      "        self.play(\n",
      "            FadeOut(vector_group),\n",
      "            FadeOut(dot_product_calc),\n",
      "            FadeOut(proj_line),\n",
      "            FadeOut(proj_text),\n",
      "            FadeOut(title),\n",
      "            FadeOut(dot_product_def),\n",
      "            FadeOut(explanation)\n",
      "        )\n",
      "\n",
      "    def cosine_similarity_section(self):\n",
      "        title = Text(\"Cosine Similarity\", font_size=60)\n",
      "        title.to_edge(UP)\n",
      "        \n",
      "        formula = MathTex(\n",
      "            r\"\\text{cosine}(v, w) = \\frac{v \\cdot w}{|v| |w|}\",\n",
      "            font_size=40\n",
      "        )\n",
      "        formula.next_to(title, DOWN, buff=0.8)\n",
      "        \n",
      "        vector_magnitude_formula = MathTex(\n",
      "            r\"|v| = \\sqrt{\\sum_{i=1}^{N} v_i^2} \\quad |w| = \\sqrt{\\sum_{i=1}^{N} w_i^2}\",\n",
      "            font_size=36\n",
      "        )\n",
      "        vector_magnitude_formula.next_to(formula, DOWN, buff=0.5)\n",
      "        \n",
      "        explanation = Text(\n",
      "            \"Cosine similarity normalizes vectors to measure the angle between them,\\n\"\n",
      "            \"focusing on direction rather than magnitude.\",\n",
      "            font_size=30\n",
      "        )\n",
      "        explanation.next_to(vector_magnitude_formula, DOWN, buff=0.5)\n",
      "        \n",
      "        self.play(Write(title))\n",
      "        self.play(Write(formula))\n",
      "        self.play(Write(vector_magnitude_formula))\n",
      "        self.play(FadeIn(explanation))\n",
      "        self.wait()\n",
      "        \n",
      "        # Visualization of cosine similarity \n",
      "        plane = NumberPlane(\n",
      "            x_range=[-3, 3, 1],\n",
      "            y_range=[-3, 3, 1],\n",
      "        ).scale(0.7)\n",
      "        plane.to_edge(DOWN, buff=0.5)\n",
      "        \n",
      "        vec1 = Vector([2, 0.5], color=BLUE, tip_length=0.2) \n",
      "        vec2 = Vector([1.5, 1.5], color=RED, tip_length=0.2)\n",
      "        \n",
      "        vec1_label = MathTex(r\"\\vec{v}\", color=BLUE).next_to(vec1.get_end(), RIGHT*0.5)\n",
      "        vec2_label = MathTex(r\"\\vec{w}\", color=RED).next_to(vec2.get_end(), UP*0.5)\n",
      "        \n",
      "        # Draw angle between vectors\n",
      "        angle = Angle(vec1, vec2, radius=0.5, color=GREEN)\n",
      "        angle_label = MathTex(r\"\\theta\", color=GREEN).move_to(\n",
      "            angle.point_from_proportion(0.5) + 0.3 * normalize(angle.point_from_proportion(0.5))\n",
      "        )\n",
      "        \n",
      "        vector_group = VGroup(plane, vec1, vec2, vec1_label, vec2_label, angle, angle_label)\n",
      "        \n",
      "        self.play(FadeIn(vector_group))\n",
      "        self.wait()\n",
      "        \n",
      "        # Show cosine similarity calculation\n",
      "        cos_calculation = MathTex(\n",
      "            r\"\\text{cosine}(\\vec{v}, \\vec{w}) &= \\frac{\\vec{v} \\cdot \\vec{w}}{|\\vec{v}| |\\vec{w}|}\\\\\",\n",
      "            r\"&= \\frac{(2, 0.5) \\cdot (1.5, 1.5)}{|(2, 0.5)| \\cdot |(1.5, 1.5)|}\\\\\",\n",
      "            r\"&= \\frac{2 \\cdot 1.5 + 0.5 \\cdot 1.5}{\\sqrt{2^2 + 0.5^2} \\cdot \\sqrt{1.5^2 + 1.5^2}}\\\\\",\n",
      "            r\"&= \\frac{3 + 0.75}{\\sqrt{4.25} \\cdot \\sqrt{4.5}}\\\\\",\n",
      "            r\"&= \\frac{3.75}{2.06 \\cdot 2.12}\\\\\",\n",
      "            r\"&= \\frac{3.75}{4.37}\\\\\",\n",
      "            r\"&\\approx 0.858\"\n",
      "        )\n",
      "        cos_calculation.scale(0.7).to_edge(RIGHT, buff=0.8)\n",
      "        \n",
      "        self.play(Write(cos_calculation), run_time=4)\n",
      "        self.wait(2)\n",
      "        \n",
      "        # Explain cosine similarity range\n",
      "        range_text = Text(\n",
      "            \"Range: [-1, 1]\\n\\n\"\n",
      "            \"1: vectors point in same direction\\n\"\n",
      "            \"0: vectors are orthogonal\\n\"\n",
      "            \"-1: vectors point in opposite directions\",\n",
      "            font_size=24\n",
      "        ).next_to(cos_calculation, DOWN, buff=0.5)\n",
      "        \n",
      "        self.play(Write(range_text))\n",
      "        self.wait(2)\n",
      "        \n",
      "        self.play(\n",
      "            FadeOut(vector_group),\n",
      "            FadeOut(cos_calculation),\n",
      "            FadeOut(range_text),\n",
      "            FadeOut(title),\n",
      "            FadeOut(formula),\n",
      "            FadeOut(vector_magnitude_formula),\n",
      "            FadeOut(explanation)\n",
      "        )\n",
      "\n",
      "    def tf_section(self):\n",
      "        title = Text(\"Term Frequency (TF)\", font_size=60)\n",
      "        title.to_edge(UP)\n",
      "        \n",
      "        definition = Text(\"Term Frequency counts how often a term occurs in a document.\", font_size=32)\n",
      "        definition.next_to(title, DOWN, buff=0.8)\n",
      "        \n",
      "        formula = MathTex(\n",
      "            r\"tf_{t,d} = \\text{count}(t,d)\", font_size=40\n",
      "        )\n",
      "        formula.next_to(definition, DOWN, buff=0.5)\n",
      "        \n",
      "        log_version = MathTex(\n",
      "            r\"tf_{t,d} = \\begin{cases} 1 + \\log_{10}(\\text{count}(t,d)) & \\text{if } \\text{count}(t,d) > 0 \\\\ 0 & \\text{otherwise} \\end{cases}\", font_size=36\n",
      "        )\n",
      "        log_version.next_to(formula, DOWN, buff=0.5)\n",
      "        \n",
      "        explanation = Text(\n",
      "            \"The logarithmic version dampens the effect of frequent terms\\n\"\n",
      "            \"and reduces the impact of high-frequency outliers.\",\n",
      "            font_size=30\n",
      "        )\n",
      "        explanation.next_to(log_version, DOWN, buff=0.5)\n",
      "        \n",
      "        self.play(Write(title))\n",
      "        self.play(FadeIn(definition))\n",
      "        self.play(Write(formula))\n",
      "        self.wait()\n",
      "        self.play(Write(log_version), run_time=2)\n",
      "        self.play(FadeIn(explanation))\n",
      "        self.wait()\n",
      "        \n",
      "        # Example visualization\n",
      "        example_title = Text(\"Example:\", font_size=32).to_edge(LEFT, buff=1).shift(DOWN*2)\n",
      "        \n",
      "        document = Text(\n",
      "            \"The cat sat on the mat. The cat was happy on the mat.\",\n",
      "            font_size=24,\n",
      "            t2c={\"cat\": BLUE, \"mat\": RED, \"The\": GREEN, \"the\": GREEN}\n",
      "        ).next_to(example_title, DOWN, buff=0.5)\n",
      "        \n",
      "        table = MobjectTable(\n",
      "            [\n",
      "                [Text(\"Term\", font_size=24), Text(\"Count\", font_size=24), Text(\"TF\", font_size=24), Text(\"Log TF\", font_size=24)],\n",
      "                [Text(\"the/The\", font_size=24, color=GREEN), Text(\"4\", font_size=24), Text(\"4\", font_size=24), Text(\"1.60\", font_size=24)],\n",
      "                [Text(\"cat\", font_size=24, color=BLUE), Text(\"2\", font_size=24), Text(\"2\", font_size=24), Text(\"1.30\", font_size=24)],\n",
      "                [Text(\"mat\", font_size=24, color=RED), Text(\"2\", font_size=24), Text(\"2\", font_size=24), Text(\"1.30\", font_size=24)],\n",
      "                [Text(\"sat\", font_size=24), Text(\"1\", font_size=24), Text(\"1\", font_size=24), Text(\"1.00\", font_size=24)],\n",
      "                [Text(\"was\", font_size=24), Text(\"1\", font_size=24), Text(\"1\", font_size=24), Text(\"1.00\", font_size=24)],\n",
      "                [Text(\"on\", font_size=24), Text(\"2\", font_size=24), Text(\"2\", font_size=24), Text(\"1.30\", font_size=24)],\n",
      "                [Text(\"happy\", font_size=24), Text(\"1\", font_size=24), Text(\"1\", font_size=24), Text(\"1.00\", font_size=24)],\n",
      "            ],\n",
      "            include_outer_lines=True\n",
      "        ).scale(0.8)\n",
      "        \n",
      "        table.next_to(document, DOWN, buff=0.5)\n",
      "        \n",
      "        self.play(Write(example_title))\n",
      "        self.play(Write(document))\n",
      "        self.play(Create(table), run_time=2)\n",
      "        self.wait(2)\n",
      "        \n",
      "        # Highlight log transformation\n",
      "        highlight_rect = SurroundingRectangle(table.get_columns()[3], color=YELLOW)\n",
      "        self.play(Create(highlight_rect))\n",
      "        self.wait()\n",
      "        self.play(FadeOut(highlight_rect))\n",
      "        \n",
      "        self.wait()\n",
      "        self.play(\n",
      "            FadeOut(title),\n",
      "            FadeOut(definition),\n",
      "            FadeOut(formula),\n",
      "            FadeOut(log_version),\n",
      "            FadeOut(explanation),\n",
      "            FadeOut(example_title),\n",
      "            FadeOut(document),\n",
      "            FadeOut(table)\n",
      "        )\n",
      "\n",
      "    def idf_section(self):\n",
      "        title = Text(\"Inverse Document Frequency (IDF)\", font_size=60)\n",
      "        title.to_edge(UP)\n",
      "        \n",
      "        definition = Text(\n",
      "            \"IDF measures the importance of a term by reducing the weight\\n\"\n",
      "            \"of common terms that appear in many documents.\",\n",
      "            font_size=32\n",
      "        )\n",
      "        definition.next_to(title, DOWN, buff=0.8)\n",
      "        \n",
      "        formula = MathTex(\n",
      "            r\"\\text{idf}_t = \\log_{10} \\left( \\frac{N}{df_t} \\right)\",\n",
      "            font_size=40\n",
      "        )\n",
      "        formula.next_to(definition, DOWN, buff=0.5)\n",
      "        \n",
      "        explanation = VGroup(\n",
      "            Text(\"where:\", font_size=30),\n",
      "            Text(\"• N = total number of documents in the corpus\", font_size=30),\n",
      "            Text(\"• df_t = number of documents containing term t\", font_size=30)\n",
      "        ).arrange(DOWN, aligned_edge=LEFT)\n",
      "        explanation.next_to(formula, DOWN, buff=0.5)\n",
      "        \n",
      "        self.play(Write(title))\n",
      "        self.play(FadeIn(definition))\n",
      "        self.play(Write(formula))\n",
      "        self.play(Write(explanation, run_time=2))\n",
      "        self.wait()\n",
      "        \n",
      "        # Example calculation\n",
      "        example = VGroup(\n",
      "            Text(\"Example:\", font_size=32),\n",
      "            Text(\"• Corpus size N = 1,000,000 documents\", font_size=28),\n",
      "            Text(\"• Term \\\"the\\\" appears in 1,000,000 documents\", font_size=28),\n",
      "            Text(\"• Term \\\"neural\\\" appears in 1,000 documents\", font_size=28)\n",
      "        ).arrange(DOWN, aligned_edge=LEFT)\n",
      "        example.to_edge(LEFT, buff=1).shift(DOWN*2)\n",
      "        \n",
      "        self.play(Write(example))\n",
      "        self.wait()\n",
      "        \n",
      "        calculation1 = MathTex(\n",
      "            r\"\\text{idf}_{\\text{the}} &= \\log_{10} \\left( \\frac{1,000,000}{1,000,000} \\right)\\\\\",\n",
      "            r\"&= \\log_{10}(1)\\\\\",\n",
      "            r\"&= 0\"\n",
      "        )\n",
      "        calculation1.next_to(example, RIGHT, buff=1)\n",
      "        \n",
      "        calculation2 = MathTex(\n",
      "            r\"\\text{idf}_{\\text{neural}} &= \\log_{10} \\left( \\frac{1,000,000}{1,000} \\right)\\\\\",\n",
      "            r\"&= \\log_{10}(1,000)\\\\\",\n",
      "            r\"&= 3\"\n",
      "        )\n",
      "        calculation2.next_to(calculation1, RIGHT, buff=1)\n",
      "        \n",
      "        self.play(Write(calculation1))\n",
      "        self.wait()\n",
      "        self.play(Write(calculation2))\n",
      "        self.wait()\n",
      "        \n",
      "        # Explanation of results\n",
      "        conclusion = Text(\n",
      "            \"Common words like \\\"the\\\" get an IDF close to 0\\n\"\n",
      "            \"Rare words like \\\"neural\\\" get a higher IDF value\",\n",
      "            font_size=28\n",
      "        ).next_to(example, DOWN, buff=0.8)\n",
      "        \n",
      "        self.play(Write(conclusion))\n",
      "        self.wait(2)\n",
      "        \n",
      "        self.play(\n",
      "            FadeOut(title),\n",
      "            FadeOut(definition),\n",
      "            FadeOut(formula),\n",
      "            FadeOut(explanation),\n",
      "            FadeOut(example),\n",
      "            FadeOut(calculation1),\n",
      "            FadeOut(calculation2),\n",
      "            FadeOut(conclusion)\n",
      "        )\n",
      "\n",
      "    def tfidf_section(self):\n",
      "        title = Text(\"TF-IDF\", font_size=60)\n",
      "        title.to_edge(UP)\n",
      "        \n",
      "        definition = Text(\n",
      "            \"TF-IDF combines Term Frequency and Inverse Document Frequency\\n\"\n",
      "            \"to identify terms that are important to a document but not too common across all documents.\",\n",
      "            font_size=32\n",
      "        )\n",
      "        definition.next_to(title, DOWN, buff=0.8)\n",
      "        \n",
      "        formula = MathTex(\n",
      "            r\"w_{t,d} = tf_{t,d} \\times \\text{idf}_t\",\n",
      "            font_size=40\n",
      "        )\n",
      "        formula.next_to(definition, DOWN, buff=0.5)\n",
      "        \n",
      "        self.play(Write(title))\n",
      "        self.play(FadeIn(definition))\n",
      "        self.play(Write(formula))\n",
      "        self.wait()\n",
      "        \n",
      "        # Document vectors visualization\n",
      "        document_vectors_title = Text(\"Document Vectors\", font_size=36)\n",
      "        document_vectors_title.next_to(formula, DOWN, buff=1)\n",
      "        \n",
      "        self.play(Write(document_vectors_title))\n",
      "        \n",
      "        # Create a table showing TF-IDF vectors for two documents\n",
      "        table_data = [\n",
      "            [Text(\"Term\", font_size=24), Text(\"TF-IDF in Doc 1\", font_size=24), Text(\"TF-IDF in Doc 2\", font_size=24)],\n",
      "            [Text(\"machine\", font_size=24), Text(\"0.5\", font_size=24), Text(\"1.2\", font_size=24)],\n",
      "            [Text(\"learning\", font_size=24), Text(\"0.8\", font_size=24), Text(\"1.5\", font_size=24)],\n",
      "            [Text(\"algorithm\", font_size=24), Text(\"1.2\", font_size=24), Text(\"0.3\", font_size=24)],\n",
      "            [Text(\"neural\", font_size=24), Text(\"0.0\", font_size=24), Text(\"1.8\", font_size=24)],\n",
      "            [Text(\"computer\", font_size=24), Text(\"0.9\", font_size=24), Text(\"0.2\", font_size=24)],\n",
      "        ]\n",
      "        \n",
      "        table = MobjectTable(\n",
      "            table_data,\n",
      "            include_outer_lines=True\n",
      "        ).scale(0.8)\n",
      "        \n",
      "        table.next_to(document_vectors_title, DOWN, buff=0.5)\n",
      "        \n",
      "        self.play(Create(table))\n",
      "        self.wait()\n",
      "        \n",
      "        # Vectors in 2D space visualization\n",
      "        explanation = Text(\n",
      "            \"Each document becomes a vector in a high-dimensional space,\\n\"\n",
      "            \"with each term being a dimension.\",\n",
      "            font_size=28\n",
      "        ).next_to(table, DOWN, buff=0.5)\n",
      "        \n",
      "        self.play(Write(explanation))\n",
      "        self.wait(2)\n",
      "        \n",
      "        # Similarity example\n",
      "        similarity_title = Text(\"Document Similarity\", font_size=32)\n",
      "        similarity_formula = MathTex(\n",
      "            r\"\\text{similarity}(D_1, D_2) = \\cos(\\vec{D_1}, \\vec{D_2}) = \\frac{\\vec{D_1} \\cdot \\vec{D_2}}{|\\vec{D_1}||\\vec{D_2}|}\",\n",
      "            font_size=36\n",
      "        )\n",
      "        \n",
      "        similarity_group = VGroup(similarity_title, similarity_formula).arrange(DOWN)\n",
      "        similarity_group.next_to(explanation, DOWN, buff=0.5)\n",
      "        \n",
      "        self.play(Write(similarity_title))\n",
      "        self.play(Write(similarity_formula))\n",
      "        self.wait(2)\n",
      "        \n",
      "        self.play(\n",
      "            FadeOut(title),\n",
      "            FadeOut(definition),\n",
      "            FadeOut(formula),\n",
      "            FadeOut(document_vectors_title),\n",
      "            FadeOut(table),\n",
      "            FadeOut(explanation),\n",
      "            FadeOut(similarity_title),\n",
      "            FadeOut(similarity_formula)\n",
      "        )\n",
      "\n",
      "    def pmi_section(self):\n",
      "        title = Text(\"Pointwise Mutual Information (PMI)\", font_size=60)\n",
      "        title.to_edge(UP)\n",
      "        \n",
      "        definition = Text(\n",
      "            \"PMI measures the association between two terms by comparing \\n\"\n",
      "            \"their actual co-occurrence with their expected co-occurrence if they were independent.\",\n",
      "            font_size=32\n",
      "        )\n",
      "        definition.next_to(title, DOWN, buff=0.8)\n",
      "        \n",
      "        formula = MathTex(\n",
      "            r\"PMI(w,c) = \\log_2 \\left( \\frac{P(w,c)}{P(w)P(c)} \\right)\",\n",
      "            font_size=40\n",
      "        )\n",
      "        formula.next_to(definition, DOWN, buff=0.5)\n",
      "        \n",
      "        explanation = VGroup(\n",
      "            Text(\"where:\", font_size=30),\n",
      "            Text(\"• P(w,c) = probability of word w and context c occurring together\", font_size=28),\n",
      "            Text(\"• P(w) = probability of word w occurring\", font_size=28),\n",
      "            Text(\"• P(c) = probability of context c occurring\", font_size=28)\n",
      "        ).arrange(DOWN, aligned_edge=LEFT)\n",
      "        explanation.next_to(formula, DOWN, buff=0.5)\n",
      "        \n",
      "        self.play(Write(title))\n",
      "        self.play(FadeIn(definition))\n",
      "        self.play(Write(formula))\n",
      "        self.play(Write(explanation, run_time=2))\n",
      "        self.wait()\n",
      "        \n",
      "        # PPMI explanation\n",
      "        ppmi_title = Text(\"Positive PMI (PPMI)\", font_size=40)\n",
      "        ppmi_title.next_to(explanation, DOWN, buff=0.8)\n",
      "        \n",
      "        ppmi_formula = MathTex(\n",
      "            r\"\\text{PPMI}(w,c) = \\max \\left( \\log_2 \\left( \\frac{P(w,c)}{P(w)P(c)} \\right), 0 \\right)\",\n",
      "            font_size=36\n",
      "        )\n",
      "        ppmi_formula.next_to(ppmi_title, DOWN, buff=0.5)\n",
      "        \n",
      "        ppmi_explanation = Text(\n",
      "            \"PPMI addresses the problem of PMI's bias toward rare co-occurrences\\n\"\n",
      "            \"by setting all negative PMI values to zero.\",\n",
      "            font_size=28\n",
      "        )\n",
      "        ppmi_explanation.next_to(ppmi_formula, DOWN, buff=0.5)\n",
      "        \n",
      "        self.play(Write(ppmi_title))\n",
      "        self.play(Write(ppmi_formula))\n",
      "        self.play(FadeIn(ppmi_explanation))\n",
      "        self.wait(2)\n",
      "        \n",
      "        # Example calculation\n",
      "        example_title = Text(\"Example:\", font_size=32)\n",
      "        example_title.to_edge(LEFT, buff=1.5).shift(DOWN*4.5)\n",
      "        \n",
      "        example = VGroup(\n",
      "            Text(\"If word 'dog' and context 'pet' co-occur more often than by chance:\", font_size=24),\n",
      "            MathTex(r\"PMI(\\text{dog}, \\text{pet}) > 0\", font_size=30),\n",
      "            Text(\"If they co-occur less often than by chance:\", font_size=24),\n",
      "            MathTex(r\"PMI(\\text{dog}, \\text{computer}) < 0\", font_size=30),\n",
      "        ).arrange(DOWN, aligned_edge=LEFT)\n",
      "        example.next_to(example_title, RIGHT, buff=0.5)\n",
      "        \n",
      "        self.play(Write(example_title))\n",
      "        self.play(Write(example, run_time=3))\n",
      "        self.wait(2)\n",
      "        \n",
      "        self.play(\n",
      "            FadeOut(title),\n",
      "            FadeOut(definition),\n",
      "            FadeOut(formula),\n",
      "            FadeOut(explanation),\n",
      "            FadeOut(ppmi_title),\n",
      "            FadeOut(ppmi_formula),\n",
      "            FadeOut(ppmi_explanation),\n",
      "            FadeOut(example_title),\n",
      "            FadeOut(example)\n",
      "        )\n",
      "\n",
      "    def skipgram_section(self):\n",
      "        title = Text(\"Skip-Gram Model\", font_size=60)\n",
      "        title.to_edge(UP)\n",
      "        \n",
      "        definition = Text(\n",
      "            \"The Skip-Gram model is part of Word2Vec, which learns word embeddings\\n\"\n",
      "            \"by predicting context words given a target word.\",\n",
      "            font_size=32\n",
      "        )\n",
      "        definition.next_to(title, DOWN, buff=0.8)\n",
      "        \n",
      "        loss_formula = MathTex(\n",
      "            r\"L = -\\log P(+|w,c_{\\text{pos}}) - \\sum_{i=1}^{k} \\log P(-|w,c_{\\text{neg}_i})\",\n",
      "            font_size=40\n",
      "        )\n",
      "        loss_formula.next_to(definition, DOWN, buff=0.5)\n",
      "        \n",
      "        explanation = Text(\n",
      "            \"The model maximizes the probability of actual context words\\n\"\n",
      "            \"while minimizing the probability of negative samples.\",\n",
      "            font_size=30\n",
      "        )\n",
      "        explanation.next_to(loss_formula, DOWN, buff=0.5)\n",
      "        \n",
      "        self.play(Write(title))\n",
      "        self.play(FadeIn(definition))\n",
      "        self.play(Write(loss_formula))\n",
      "        self.play(FadeIn(explanation))\n",
      "        self.wait()\n",
      "        \n",
      "        # Word2Vec architecture visualization\n",
      "        architecture_title = Text(\"Skip-Gram Architecture\", font_size=36)\n",
      "        architecture_title.next_to(explanation, DOWN, buff=0.8)\n",
      "        \n",
      "        self.play(Write(architecture_title))\n",
      "        \n",
      "        # Architecture diagram\n",
      "        target_word = Rectangle(height=0.8, width=2, color=BLUE, fill_opacity=0.3)\n",
      "        target_word_text = Text(\"Target Word\", font_size=24).move_to(target_word)\n",
      "        \n",
      "        hidden_layer = Rectangle(height=3, width=1.5, color=GREEN, fill_opacity=0.2)\n",
      "        hidden_layer_text = Text(\"Hidden\\nLayer\", font_size=20).move_to(hidden_layer)\n",
      "        \n",
      "        context_words = VGroup()\n",
      "        for i in range(4):\n",
      "            rect = Rectangle(height=0.6, width=1.8, color=RED, fill_opacity=0.3)\n",
      "            text = Text(f\"Context {i+1}\", font_size=20).move_to(rect)\n",
      "            context_words.add(VGroup(rect, text))\n",
      "        \n",
      "        context_words.arrange(DOWN, buff=0.3)\n",
      "        \n",
      "        # Arrange the architecture\n",
      "        architecture = VGroup(\n",
      "            target_word, target_word_text,\n",
      "            hidden_layer, hidden_layer_text,\n",
      "            context_words\n",
      "        )\n",
      "        \n",
      "        # Position elements\n",
      "        hidden_layer.next_to(target_word, RIGHT, buff=1.5)\n",
      "        context_words.next_to(hidden_layer, RIGHT, buff=1.5)\n",
      "        \n",
      "        # Add arrows\n",
      "        arrow1 = Arrow(target_word.get_right(), hidden_layer.get_left(), buff=0.1)\n",
      "        arrows2 = VGroup()\n",
      "        for word in context_words:\n",
      "            arrow = Arrow(hidden_layer.get_right(), word[0].get_left(), buff=0.1)\n",
      "            arrows2.add(arrow)\n",
      "        \n",
      "        architecture_group = VGroup(architecture, arrow1, arrows2)\n",
      "        architecture_group.scale(0.9).next_to(architecture_title, DOWN, buff=0.5)\n",
      "        \n",
      "        self.play(Create(architecture_group), run_time=2)\n",
      "        self.wait()\n",
      "        \n",
      "        # Advantages of word embeddings\n",
      "        advantages_title = Text(\"Advantages of Word Embeddings\", font_size=32)\n",
      "        advantages_title.next_to(architecture_group, DOWN, buff=0.8)\n",
      "        \n",
      "        advantages = BulletedList(\n",
      "            \"Captures semantic relationships between words\",\n",
      "            \"Reduces dimensionality compared to sparse vectors\",\n",
      "            \"Enables powerful analogical reasoning: king - man + woman ≈ queen\",\n",
      "            \"Improves performance in downstream NLP tasks\",\n",
      "            font_size=24\n",
      "        )\n",
      "        advantages.next_to(advantages_title, DOWN, buff=0.3)\n",
      "        \n",
      "        self.play(Write(advantages_title))\n",
      "        self.play(Write(advantages), run_time=3)\n",
      "        self.wait(2)\n",
      "        \n",
      "        self.play(\n",
      "            FadeOut(title),\n",
      "            FadeOut(definition),\n",
      "            FadeOut(loss_formula),\n",
      "            FadeOut(explanation),\n",
      "            FadeOut(architecture_title),\n",
      "            FadeOut(architecture_group),\n",
      "            FadeOut(advantages_title),\n",
      "            FadeOut(advantages)\n",
      "        )\n",
      "\n",
      "    def conclusion_section(self):\n",
      "        title = Text(\"Summary\", font_size=60)\n",
      "        title.to_edge(UP)\n",
      "        \n",
      "        summary = BulletedList(\n",
      "            \"Vector semantics represents words as points in a multidimensional space\",\n",
      "            \"Dot product and cosine similarity measure vector relationships\",\n",
      "            \"TF-IDF weights terms based on their document importance\",\n",
      "            \"PMI and PPMI measure statistical word associations\",\n",
      "            \"Word2Vec models learn dense, meaningful word embeddings\",\n",
      "            font_size=32\n",
      "        )\n",
      "        summary.next_to(title, DOWN, buff=0.8)\n",
      "        \n",
      "        self.play(Write(title))\n",
      "        self.play(Write(summary), run_time=3)\n",
      "        self.wait()\n",
      "        \n",
      "        applications = Text(\n",
      "            \"Applications: Information Retrieval, Text Classification,\\n\"\n",
      "            \"Machine Translation, Question Answering, and more!\",\n",
      "            font_size=36,\n",
      "            color=YELLOW\n",
      "        )\n",
      "        applications.next_to(summary, DOWN, buff=0.8)\n",
      "        \n",
      "        self.play(Write(applications))\n",
      "        self.wait(2)\n",
      "        \n",
      "        thank_you = Text(\"Thank you for watching!\", font_size=48, color=BLUE)\n",
      "        thank_you.to_edge(DOWN, buff=1)\n",
      "        \n",
      "        self.play(Write(thank_you))\n",
      "        self.wait(3)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(messages[-1][\"content\"][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec62cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
