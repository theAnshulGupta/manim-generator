{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fa88f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "import os\n",
    "import base64\n",
    "import cv2\n",
    "from anthropic import AsyncAnthropic\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cebf6a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINK_PREFIX = \"https://docs.manim.community/en/stable/\"\n",
    "MEDIA_OUTPUT_DIR = \"downloaded_media\"\n",
    "SUMMARY_OUTPUT_DIR = \"summary\"\n",
    "INPUT_DIR = \"page_content\"\n",
    "\n",
    "client = AsyncAnthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97eb846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_to_file_name(link):\n",
    "    return link[39:].replace('/', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b13029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_and_media(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    soup = BeautifulSoup(data, \"html.parser\")\n",
    "    media_tags = soup.find_all([\"img\", \"video\"])\n",
    "    marker = \"<<<MEDIA>>>\"\n",
    "    media_list = []\n",
    "\n",
    "    # Get images and replace all of them with marker\n",
    "    for tag in media_tags:\n",
    "        if tag.name == \"img\":\n",
    "            src = tag.get(\"src\") or tag.get(\"data‑src\")\n",
    "            media_list.append((\"image\", src))\n",
    "        else:\n",
    "            src = tag.get(\"src\")\n",
    "            if not src and tag.find(\"source\"):\n",
    "                src = tag.find(\"source\").get(\"src\")\n",
    "            media_list.append((\"video\", src))\n",
    "        tag.replace_with(marker)\n",
    "\n",
    "    # Get all the texts and split based on marker\n",
    "    full_text = soup.get_text()\n",
    "    parts = [piece.strip() for piece in full_text.split(marker)]\n",
    "\n",
    "    # Interleave\n",
    "    result = []\n",
    "    for i, media in enumerate(media_list):\n",
    "        if parts[i]:\n",
    "            result.append((\"text\", parts[i]))\n",
    "        result.append(media)\n",
    "    if len(parts) > len(media_list) and parts[-1]:\n",
    "        result.append((\"text\", parts[-1]))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1e58249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images_and_videos(url, content):\n",
    "    session = requests.Session()\n",
    "\n",
    "    for t, info in content:\n",
    "        if t == \"image\" or t == \"video\":\n",
    "            full_url = urljoin(url, info)\n",
    "            response = session.get(full_url)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                with open(f\"{MEDIA_OUTPUT_DIR}/{link_to_file_name(full_url)}\", \"wb\") as f:\n",
    "                    f.write(response.content)\n",
    "                print(f\"[saved] {link_to_file_name(full_url)}\")\n",
    "            else:\n",
    "                print(f\"[failed] {full_url} (status code {response.status_code})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c237cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_message_with_media(url, content):\n",
    "    message_content = []\n",
    "\n",
    "    for t, info in content:\n",
    "        if t == \"image\":\n",
    "            full_url = urljoin(url, info)\n",
    "            path = os.path.join(MEDIA_OUTPUT_DIR, link_to_file_name(full_url))\n",
    "\n",
    "            # No svg\n",
    "            if path[-3:] == \"svg\":\n",
    "                continue\n",
    "\n",
    "            with open(path, \"rb\") as f:\n",
    "                image_data = f.read()\n",
    "\n",
    "            message_content.append({\n",
    "                \"type\": \"image\",\n",
    "                \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": \"image/png\",\n",
    "                    \"data\": base64.standard_b64encode(image_data).decode(\"utf-8\"),\n",
    "                }\n",
    "            })\n",
    "\n",
    "        elif t == \"video\":\n",
    "            # Extract middle frame\n",
    "            full_url = urljoin(url, info)\n",
    "            path = os.path.join(MEDIA_OUTPUT_DIR, link_to_file_name(full_url))\n",
    "            cap = cv2.VideoCapture(path)\n",
    "            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            middle_frame_idx = frame_count // 2\n",
    "\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, middle_frame_idx)\n",
    "            _, frame = cap.read()\n",
    "            cap.release()\n",
    "            _, buffer = cv2.imencode(\".png\", frame)\n",
    "            image_data = buffer.tobytes()\n",
    "\n",
    "            message_content.append({\n",
    "                \"type\": \"image\",\n",
    "                \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": \"image/png\",\n",
    "                    \"data\": base64.standard_b64encode(image_data).decode(\"utf-8\"),\n",
    "                }\n",
    "            })\n",
    "        else:\n",
    "            message_content.append({ \"type\": \"text\", \"text\": info })\n",
    "    \n",
    "    return { \"role\": \"user\", \"content\": message_content }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f906082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_save():\n",
    "    for file_name in os.listdir(INPUT_DIR):\n",
    "        path = os.path.join(INPUT_DIR, file_name)\n",
    "        \n",
    "        with open(path, \"rb\") as f:\n",
    "            url = f.readline().decode('utf-8').strip()\n",
    "        \n",
    "        content = extract_text_and_media(path)\n",
    "        save_images_and_videos(url, content)\n",
    "\n",
    "# run_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18e92cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexl\\AppData\\Local\\Temp\\ipykernel_20628\\1333839310.py:1: RuntimeWarning: coroutine 'AsyncMessages.create' was never awaited\n",
      "  results = []\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "100%|██████████| 539/539 [01:46<00:00,  5.06it/s]\n",
      "100%|██████████| 539/539 [1:27:58<00:00,  9.79s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for file_name in tqdm(os.listdir(INPUT_DIR)):\n",
    "    path = os.path.join(INPUT_DIR, file_name)\n",
    "        \n",
    "    with open(path, \"rb\") as f:\n",
    "        url = f.readline().decode('utf-8').strip()\n",
    "        \n",
    "    content = extract_text_and_media(path)\n",
    "    user_message = [construct_message_with_media(url, content)]\n",
    "        \n",
    "    query = client.messages.create(\n",
    "        model=\"claude-3-5-haiku-20241022\",\n",
    "        temperature=1,\n",
    "        max_tokens=8192,\n",
    "        system=\"You are an expert technical writer. You will be given the content of some documentation for the Manim library. Please summarize the information very succinctly while also making sure that nothing is left out. Minimizing number of characters is of high importance here, keep everything in around 1 paragraph unless the information is actually really important! Furthermore, if something isn't of importance to the actual documentation (e.g. changelog, how to contribute, etc.) just say 'Not Relevant' and don't output a summary <-- very important (e.g. say 'Not Relevant' for changelog stuffs). Output only the summary/response and nothing more -- NO commentary\",\n",
    "        messages=user_message\n",
    "    )\n",
    "    results.append((file_name, query))\n",
    "\n",
    "for file_name, query in tqdm(results):\n",
    "    query = await query\n",
    "    info = query.content[0].text\n",
    "\n",
    "    with open(os.path.join(SUMMARY_OUTPUT_DIR, file_name.replace(\"html\", \"txt\")), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35615ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
